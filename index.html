<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Understanding Language Models (NLP)</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;600;700&display=swap" rel="stylesheet">
    <style>
        body {
            font-family: 'Inter', sans-serif;
            background-color: #f3f4f6;
            color: #1f2937;
            display: flex;
            flex-direction: column;
            align-items: center;
            justify-content: center;
            min-height: 100vh;
            margin: 0;
            padding: 1rem;
            box-sizing: border-box;
        }
        .slide-container {
            background-color: white;
            border-radius: 12px;
            box-shadow: 0 10px 25px rgba(0, 0, 0, 0.1);
            padding: 2rem;
            width: 100%;
            max-width: 800px;
            min-height: 450px; /* Adjusted min height as images are removed */
            display: flex;
            flex-direction: column;
            justify-content: space-between;
            transition: opacity 0.5s ease-in-out;
        }
        .slide {
            display: none; 
            animation: fadeIn 0.5s;
        }
        .slide.active {
            display: block; 
        }
        @keyframes fadeIn {
            from { opacity: 0; transform: translateY(10px); }
            to { opacity: 1; transform: translateY(0); }
        }
        h1, h2, h3 {
            color: #1e40af; 
        }
        h1 { font-size: 2.25rem; margin-bottom: 1rem; text-align: center; }
        h2 { font-size: 1.75rem; margin-bottom: 0.75rem; margin-top: 1.5rem; }
        h3 { font-size: 1.25rem; margin-bottom: 0.5rem; margin-top: 1rem; color: #1d4ed8; }
        p, ul, ol {
            font-size: 1rem;
            line-height: 1.6;
            margin-bottom: 1rem;
        }
        ul {
            list-style-type: disc;
            padding-left: 1.5rem;
        }
        ol {
            list-style-type: decimal;
            padding-left: 1.5rem;
        }
        strong, b {
            font-weight: 600; /* Tailwind's font-semibold equivalent */
        }
        .nav-controls {
            display: flex;
            justify-content: space-between;
            align-items: center;
            margin-top: 1.5rem;
            padding: 1rem;
            background-color: #e5e7eb;
            border-radius: 8px;
            width: 100%;
            max-width: 800px;
        }
        .nav-button {
            background-color: #2563eb;
            color: white;
            padding: 0.75rem 1.5rem;
            border: none;
            border-radius: 8px;
            cursor: pointer;
            font-weight: 600;
            transition: background-color 0.3s ease;
        }
        .nav-button:hover {
            background-color: #1d4ed8;
        }
        .nav-button:disabled {
            background-color: #9ca3af;
            cursor: not-allowed;
        }
        .slide-counter {
            font-size: 0.9rem;
            color: #4b5563;
        }
        .analogy-toggle {
            background-color: #d1fae5;
            color: #065f46;
            padding: 0.5rem 1rem;
            border-radius: 6px;
            cursor: pointer;
            display: inline-block;
            margin-top: 0.5rem;
            font-weight: 600;
        }
        .analogy-content {
            background-color: #e0f2fe;
            color: #0c4a6e;
            padding: 1rem;
            border-radius: 8px;
            margin-top: 0.5rem;
            border-left: 4px solid #3b82f6;
        }
        .chapter-title-slide h2 {
            font-size: 2rem;
            text-align: center;
            margin-top: 2rem;
            margin-bottom: 2rem;
        }
        .note-section {
            background-color: #fef9c3; /* Light yellow */
            color: #713f12; /* Brown text */
            padding: 1rem;
            border-radius: 8px;
            margin-top: 1.5rem;
            border-left: 4px solid #facc15; /* Yellow accent */
            display: flex;
            align-items: flex-start; /* Align icon and text nicely */
        }
        .note-section svg {
            flex-shrink: 0; /* Prevent icon from shrinking */
            margin-right: 0.75rem; /* Space between icon and text */
            width: 24px;
            height: 24px;
            fill: #f59e0b; /* Amber color for bulb */
        }

        /* Responsive adjustments */
        @media (max-width: 640px) {
            body { padding: 0.5rem; }
            .slide-container { padding: 1rem; min-height: auto; }
            h1 { font-size: 1.8rem; }
            h2 { font-size: 1.5rem; }
            h3 { font-size: 1.1rem; }
            p, ul, ol { font-size: 0.9rem; }
            .nav-controls { flex-direction: column; gap: 0.5rem; }
            .nav-button { width: 100%; }
        }
    </style>
</head>
<body>

    <h1>Understanding Language Models (NLP)</h1>

    <div class="slide-container">
        </div>

    <div class="nav-controls">
        <button id="prevBtn" class="nav-button">Previous</button>
        <span id="slideCounter" class="slide-counter">Slide 1 / N</span>
        <button id="nextBtn" class="nav-button">Next</button>
    </div>

    <script>
        // SVG Bulb Icon
        const bulbIconSvg = `
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
                <path d="M12 2c2.21 0 4 1.79 4 4s-1.79 4-4 4-4-1.79-4-4 1.79-4 4-4zm0 10c-2.67 0-8 1.34-8 4v2h16v-2c0-2.66-5.33-4-8-4zm0-8c-1.1 0-2 .9-2 2s.9 2 2 2 2-.9 2-2-.9-2-2-2zm0 10c-1.33 0-4 .67-4 2h8c0-1.33-2.67-2-4-2zm0-2.5c.83 0 1.5.67 1.5 1.5s-.67 1.5-1.5 1.5-1.5-.67-1.5-1.5.67-1.5 1.5-1.5zM9 19h6v-1.08c0-.7-.56-1.25-1.29-1.09-.47.11-.93.17-1.39.17s-.92-.06-1.39-.17C10.15 16.67 9 17.22 9 17.92V19zm3-14.5c-1.93 0-3.5 1.57-3.5 3.5S10.07 11.5 12 11.5s3.5-1.57 3.5-3.5S13.93 4.5 12 4.5z"/>
                <path d="M12,2A7,7,0,0,0,5,9c0,2.38,1.19,4.47,3,5.74V17a1,1,0,0,0,1,1h6a1,1,0,0,0,1-1v-2.26c1.81-1.27,3-3.36,3-5.74A7,7,0,0,0,12,2Zm1,15H11v-1h2Zm0-3H11V12h2ZM12,6a3,3,0,1,1-3,3A3,3,0,0,1,12,6Z"/>
            </svg>
        `; // A more distinct bulb icon

        const slidesContent = [
            // Introduction Slide
            {
                title: "Welcome!",
                content: `
                    <div class="text-center">
                        <h2 class="text-3xl font-bold text-blue-700 mb-6">Journey into Language Models</h2>
                        <p class="text-lg text-gray-700 mb-4">This presentation will guide you through the fascinating world of <strong>Language Models</strong>, from the basics to the advanced concepts that power today's AI.</p>
                        <p class="text-lg text-gray-700">We'll use <strong>simple terms</strong> and <strong>analogies</strong> to make complex ideas easy to understand. Let's begin!</p>
                    </div>
                `
            },
            // Chapter 1: What is an LLM?
            {
                title: "Chapter 1: What is an LLM?",
                isChapterTitle: true,
                content: `<h2 class="text-center">Chapter 1: What is a <strong>Large Language Model (LLM)</strong>?</h2>`
            },
            {
                title: "LLM: Super-Smart Autocomplete",
                content: `
                    <h3>LLM: A <strong>Super-Smart Autocomplete</strong></h3>
                    <p>Imagine you're texting and your phone suggests the next word. An LLM is like that, but on a <strong>massive scale</strong>.</p>
                    <p>It's an incredibly well-read system, trained on <strong>trillions of words</strong> from books, articles, websites, and conversations. This vast amount of text is far more than any single human could ever read!</p>
                    <p><strong>Example:</strong> If you type "The weather today is...", an LLM might predict "...sunny and warm." or "...cloudy with a chance of rain." based on patterns it learned.</p>
                `
            },
            {
                title: "LLM: Learning from Text",
                content: `
                    <h3>How LLMs Learn Patterns</h3>
                    <p>Because it has "read" so much, an LLM learns:</p>
                    <ul>
                        <li>Patterns of how <strong>words fit together</strong>.</li>
                        <li>How <strong>sentences are formed</strong> (grammar and syntax).</li>
                        <li>How different <strong>ideas and concepts relate</strong> to each other.</li>
                    </ul>
                    <p>It's like someone who has read every book in the world's biggest library and remembers not just the stories, but how language is used to tell them.</p>
                    <div class="note-section">
                        ${bulbIconSvg}
                        <div><strong>Note:</strong> LLMs don't "understand" in a human sense. They are exceptionally good at recognizing and reproducing <strong>statistical patterns</strong> in the data they were trained on.</div>
                    </div>
                `
            },
            {
                title: "LLM: Capabilities",
                content: `
                    <h3>What Can This "Super-Smart Autocomplete" Do?</h3>
                    <ul>
                        <li><strong>Predict the next word/sentence:</strong> Far more sophisticated than basic autocomplete.</li>
                        <li><strong>Understand your questions:</strong> Processes queries in plain English (or other languages).</li>
                        <li><strong>Generate text:</strong> Can write emails, summaries, stories, poems, and even computer code. <em>For example, you could ask it to "Write a short poem about a cat."</em></li>
                        <li><strong>Translate languages:</strong> By learning patterns in multiple languages.</li>
                        <li><strong>Answer questions:</strong> Uses its vast knowledge from training data.</li>
                    </ul>
                `
            },
            {
                title: "LLM: Analogy",
                content: `
                    <h3>Analogy: The <strong>Master Chef</strong></h3>
                    <div class="analogy-toggle" onclick="toggleAnalogy(this)" data-analogy-name="The Master Chef">Reveal: The Master Chef</div>
                    <div class="analogy-content hidden">
                        <p>Imagine a master chef who has studied every recipe, technique, and flavor combination. This chef has an incredible understanding of food.</p>
                        <ul>
                            <li>Ask "What usually goes well with chicken?" – they'll have tons of suggestions (like an LLM understanding <strong>word relationships</strong>).</li>
                            <li>Say "I want to make a dessert that's sweet but also a bit tart" – they can come up with a recipe (like an LLM <strong>generating text</strong> based on a prompt).</li>
                            <li>Give them a list of ingredients – they can tell you what you can make (like an LLM <strong>understanding input</strong> and providing relevant output).</li>
                        </ul>
                        <p>An LLM is like that master chef, but for language and information.</p>
                    </div>
                    <div class="note-section">
                        ${bulbIconSvg}
                        <div><strong>Note:</strong> An LLM doesn't "think" or "feel" like a human chef. It's a powerful tool built on the <strong>patterns</strong> it learned from all that text. Its "creativity" is a result of sophisticated pattern matching and generation.</div>
                    </div>
                `
            },
            // Chapter 2: What is a Language Model?
            {
                title: "Chapter 2: What is a Language Model?",
                isChapterTitle: true,
                content: `<h2 class="text-center">Chapter 2: What is a <strong>Language Model</strong>?</h2>`
            },
            {
                title: "Language Model: The Rulebook",
                content: `
                    <h3>The <strong>Rulebook</strong> or <strong>Probability Guide</strong> for Language</h3>
                    <p>Before LLMs, we had the basic "Language Model." Its main job is to figure out <strong>how likely a sequence of words is to occur</strong>.</p>
                    <p>Consider these sentences:</p>
                    <ol>
                        <li class="text-green-700 p-1 bg-green-100 rounded-md">"The fluffy cat sat on the mat." (<strong>High probability</strong>)</li>
                        <li class="text-red-700 p-1 bg-red-100 rounded-md">"Sat mat cat fluffy on the the." (<strong>Low probability</strong>)</li>
                    </ol>
                    <p>A language model assigns a higher probability (a higher score) to the first sentence because it follows the <strong>common patterns and rules</strong> of English.</p>
                `
            },
            {
                title: "Language Model: How It Learns",
                content: `
                    <h3>How Does It Learn These "Rules"?</h3>
                    <p>It learns them by looking at <strong>a lot of text</strong> (though typically less than an LLM). Even a simpler language model is trained on text data. By seeing many examples of correct sentences, it starts to understand:</p>
                    <ul>
                        <li>Which words tend to <strong>follow other words</strong> (e.g., "thank" is often followed by "you").</li>
                        <li>Basic <strong>grammar</strong> (e.g., subjects usually come before verbs).</li>
                        <li><strong>Common phrases</strong>.</li>
                    </ul>
                    <div class="note-section">
                        ${bulbIconSvg}
                        <div><strong>Note:</strong> The "rules" aren't explicitly programmed. The model <strong>infers these statistical likelihoods</strong> from the data.</div>
                    </div>
                `
            },
            {
                title: "Language Model: Analogy",
                content: `
                    <h3>Analogy: The <strong>Weather Forecaster for Words</strong></h3>
                    <div class="analogy-toggle" onclick="toggleAnalogy(this)" data-analogy-name="Word Weather Forecaster">Reveal: Word Weather Forecaster</div>
                    <div class="analogy-content hidden">
                        <p>Think of a weather forecaster. They look at <strong>past weather patterns</strong> (historical data) to predict what the weather will be like tomorrow. They might say, "There's a 70% chance of rain."</p>
                        <p>A language model is a bit like that, but for words:</p>
                        <ul>
                            <li>If it sees "The sky is blue and the sun is...", it can predict that the next word is likely to be "<strong>shining</strong>" with a high probability.</li>
                            <li>If it sees "I am going to the...", it knows that "<strong>park</strong>," "<strong>store</strong>," or "<strong>movies</strong>" are more probable next words than, say, "<strong>purple</strong>."</li>
                        </ul>
                    </div>
                    <p class="mt-4">So, a language model essentially gives us a way to <strong>quantify how "good" or "likely"</strong> a piece of text is.</p>
                `
            },
            {
                title: "Language Model: Applications",
                content: `
                    <h3>Applications of Language Models:</h3>
                    <ul>
                        <li><strong>Spell checkers:</strong> Suggest corrections by finding the most probable correct word in context. <em>Example: If you type "I went to the bech," it might suggest "beach."</em></li>
                        <li><strong>Autocomplete:</strong> Your phone's keyboard uses a language model.</li>
                        <li><strong>Machine translation:</strong> Understanding sentence probabilities in different languages helps translate more accurately.</li>
                    </ul>
                    <div class="note-section">
                        ${bulbIconSvg}
                        <div><strong>Note:</strong> The "<strong>Large</strong>" in LLM simply means it's a language model that has been trained on an <strong>enormous amount of text</strong> and has a huge number of internal "parameters" (learned settings). This scale allows for much more nuanced understanding.</div>
                    </div>
                `
            },
            // Chapter 3: The Journey
            {
                title: "Chapter 3: The Journey of Understanding Words",
                isChapterTitle: true,
                content: `<h2 class="text-center">Chapter 3: The Journey of Understanding Words</h2><p class="text-center text-lg">From Simple Dictionaries to Storytellers</p>`
            },
            {
                title: "Part 1: Word2Vec",
                content: `
                    <h3>Part 1: <strong>Word2Vec</strong> - Giving Words a Location in "Meaning Space"</h3>
                    <p><strong>The Old Way:</strong> Computers saw words as just sequences of letters (e.g., "King" was K-I-N-G).</p>
                    <p><strong>The Idea (Word2Vec):</strong> Give each word an "address" or <strong>coordinates</strong> in a giant "<strong>meaning space</strong>." Words with similar meanings are close together.</p>
                    <p><strong>How it Worked:</strong> Learned these "addresses" by looking at which words tend to <strong>appear near each other</strong> in sentences. <em>Example: "Dog" often appears with "barked," "cat" with "meowed."</em></p>
                    <p><strong>The Magic:</strong> It could even do "math" with words! For example, "King" - "Man" + "Woman" would result in coordinates very close to "Queen." This showed it captured <strong>semantic relationships</strong>.</p>
                    <div class="analogy-toggle" onclick="toggleAnalogy(this)" data-analogy-name="The Constellation Mapper">Reveal: The Constellation Mapper</div>
                    <div class="analogy-content hidden">
                        <p>Imagine an astronomer mapping stars. Stars that are part of the same constellation (related) are grouped together. Word2Vec is like a constellation mapper for words, grouping them based on how they're used together.</p>
                    </div>
                    <p class="mt-2"><strong>Limitation:</strong> Great for individual word meanings, but didn't understand the <strong>order of words</strong> or sentence structure well.</p>
                `
            },
            {
                title: "Part 2: RNNs",
                content: `
                    <h3>Part 2: <strong>RNNs</strong> - Remembering the Story So Far</h3>
                    <p><strong>The Challenge:</strong> Language isn't just a bag of words; it's a <strong>sequence</strong>. The order matters! ("I am happy" vs. "I am not happy").</p>
                    <p><strong>The Idea (Recurrent Neural Networks - RNNs):</strong> Designed to <strong>remember what they've seen before</strong> in a sequence. As they process a sentence word by word, they keep a kind of "<strong>memory</strong>" of the previous words. This memory helps them understand context.</p>
                    <p><strong>How it Worked:</strong> It has a loop. It processes a word, produces an output, and then feeds a summary of what it just processed back into itself to consider for the next word.</p>
                    <div class="analogy-toggle" onclick="toggleAnalogy(this)" data-analogy-name="Choose-Your-Own-Adventure Book">Reveal: Choose-Your-Own-Adventure Book</div>
                    <div class="analogy-content hidden">
                        <p>In these books, what happens next depends on your previous choices. You have to remember the path you took. An RNN is like a reader who remembers the story so far to understand the current page.</p>
                    </div>
                    <p class="mt-2"><strong>Limitation:</strong> RNNs had a "<strong>short-term memory</strong>" problem. They struggled to remember important context from much earlier in a long sentence or paragraph.</p>
                     <div class="note-section">
                        ${bulbIconSvg}
                        <div><strong>Note:</strong> This memory issue is often called the "<strong>vanishing gradient problem</strong>," where the influence of earlier words diminishes too quickly as the sequence gets longer.</div>
                    </div>
                `
            },
            {
                title: "Part 3: Transformers",
                content: `
                    <h3>Part 3: <strong>Transformers</strong> - Paying Attention to What Matters</h3>
                    <p><strong>The Next Hurdle:</strong> RNNs' memory problem. How to understand long sentences and pay attention to important words, even if they are far apart?</p>
                    <p><strong>The Idea (Transformers & "Attention"):</strong> Instead of processing words one by one, Transformers can look at <strong>all words in a sentence at the same time</strong>. A mechanism called "<strong>attention</strong>" figures out which words are most important to understand the meaning of any given word in that context.</p>
                    <p><strong>How "Attention" Worked:</strong> For each word, it weighs the relevance of all other words in the sentence. <em>Example: In "The dog, which ran all day, was tired," for "tired," "attention" would highlight "dog" and "ran all day."</em></p>
                    <p><strong>The Magic:</strong> Handles <strong>long-range dependencies</strong> (connections between distant words) much better. Also, can process many words in <strong>parallel</strong> (at the same time), making them much faster to train.</p>
                    <div class="analogy-toggle" onclick="toggleAnalogy(this)" data-analogy-name="Expert Panel Discussion">Reveal: Expert Panel Discussion</div>
                    <div class="analogy-content hidden">
                        <p>Imagine a panel of experts (words). For any point, you can instantly ask all experts how their area relates. "Attention" is like a moderator highlighting which experts (other words) are most relevant to the current speaker (current word).</p>
                    </div>
                `
            },
            {
                title: "The Journey's Impact",
                content: `
                    <h3>The Journey's Impact</h3>
                    <p>This progression has been revolutionary:</p>
                    <ol class="space-y-2 my-2">
                        <li><strong>Word2Vec:</strong> Gave individual words rich meaning.</li>
                        <li><strong>RNNs:</strong> Understood sequences and short-term context.</li>
                        <li><strong>Transformers:</strong> Mastered long-range context with <strong>attention</strong> and enabled training on massive datasets due to <strong>parallel processing</strong>.</li>
                    </ol>
                    <div class="note-section">
                        ${bulbIconSvg}
                        <div><strong>Note:</strong> Transformers are the architectural foundation for most modern <strong>Large Language Models (LLMs)</strong> like GPT, BERT, and others. Their ability to scale and handle complex language patterns is key to their success.</div>
                    </div>
                `
            },
            // Conclusion Slide
            {
                title: "Thank You!",
                content: `
                    <div class="text-center">
                        <h2 class="text-3xl font-bold text-blue-700 mb-6">You've Reached the End!</h2>
                        <p class="text-lg text-gray-700 mb-4">Hopefully, this journey through language models has been insightful and easy to follow.</p>
                        <p class="text-lg text-gray-700">These concepts are the <strong>building blocks</strong> for many amazing AI technologies we see today. Understanding them helps demystify how AI "understands" and generates language.</p>
                    </div>
                `
            }
        ];

        let currentSlideIndex = 0;
        const slideContainer = document.querySelector('.slide-container');
        const prevBtn = document.getElementById('prevBtn');
        const nextBtn = document.getElementById('nextBtn');
        const slideCounterEl = document.getElementById('slideCounter');

        function renderSlides() {
            slideContainer.innerHTML = '';
            slidesContent.forEach((slideData) => {
                const slideEl = document.createElement('div');
                slideEl.classList.add('slide');
                if (slideData.isChapterTitle) {
                    slideEl.classList.add('chapter-title-slide');
                }
                slideEl.innerHTML = slideData.content; 
                slideContainer.appendChild(slideEl);
            });
            showSlide(currentSlideIndex);
        }

        function showSlide(index) {
            const slides = document.querySelectorAll('.slide');
            slides.forEach((slide, i) => {
                slide.classList.toggle('active', i === index);
            });
            updateNavControls();
            slideCounterEl.textContent = `Slide ${index + 1} / ${slides.length}`;
        }

        function updateNavControls() {
            prevBtn.disabled = currentSlideIndex === 0;
            nextBtn.disabled = currentSlideIndex === slidesContent.length - 1;
        }

        function toggleAnalogy(element) {
            const content = element.nextElementSibling;
            if (!content || !content.classList) {
                return;
            }
            const isHidden = content.classList.toggle('hidden'); 
            const analogyName = element.dataset.analogyName || 'Analogy';
            element.textContent = isHidden ? `Reveal: ${analogyName}` : `Hide: ${analogyName}`;
        }
        
        prevBtn.addEventListener('click', () => {
            if (currentSlideIndex > 0) {
                currentSlideIndex--;
                showSlide(currentSlideIndex);
            }
        });

        nextBtn.addEventListener('click', () => {
            if (currentSlideIndex < slidesContent.length - 1) {
                currentSlideIndex++;
                showSlide(currentSlideIndex);
            }
        });

        document.addEventListener('DOMContentLoaded', renderSlides);
    </script>

</body>
</html>
